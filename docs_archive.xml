<?xml version="1.0" ?>
<documentation>
  <metadata>
    <created_at>2025-03-06 16:37:25</created_at>
    <crawler_version>1.0</crawler_version>
    <start_url>https://ai.google.dev/gemini-api/docs/text-generation?lang=python</start_url>
    <pages_crawled>0</pages_crawled>
    <max_depth>5</max_depth>
  </metadata>
  <page url="https://ai.google.dev/gemini-api/docs/text-generation?lang=python">
    <title>Text generation | Gemini API | Google AI for Developers</title>
    <content>
      <heading level="2">Generate text from text-only input</heading>
      <paragraph>The simplest way to generate text using the Gemini API is to provide the model with a single text-only input, as shown in this example:</paragraph>
      <paragraph>In this case, the prompt (&quot;Explain how AI works&quot;) doesn't include any output examples, system instructions, or formatting information. It's a zero-shot approach. For some use cases, a one-shot or few-shot prompt might produce output that's more aligned with user expectations. In some cases, you might also want to provide system instructions to help the model understand the task or follow specific guidelines.</paragraph>
      <heading level="2">Generate text from text-and-image input</heading>
      <paragraph>The Gemini API supports multimodal inputs that combine text and media files. The following example shows how to generate text from text-and-image input:</paragraph>
      <heading level="2">Generate a text stream</heading>
      <paragraph>By default, the model returns a response after completing the entire text generation process. You can achieve faster interactions by not waiting for the entire result, and instead use streaming to handle partial results.</paragraph>
      <paragraph>The following example shows how to implement streaming using the streamGenerateContent method to generate text from a text-only input prompt.</paragraph>
      <heading level="2">Create a chat conversation</heading>
      <paragraph>The Gemini SDK lets you collect multiple rounds of questions and responses, allowing users to step incrementally toward answers or get help with multipart problems. This SDK feature provides an interface to keep track of conversations history, but behind the scenes uses the same generateContent method to create the response.</paragraph>
      <paragraph>The following code example shows a basic chat implementation:</paragraph>
      <paragraph>You can also use streaming with chat, as shown in the following example:</paragraph>
      <heading level="2">Configure text generation</heading>
      <paragraph>Every prompt you send to the model includes parameters that control how the model generates responses. You can use GenerationConfig to configure these parameters. If you don't configure the parameters, the model uses default options, which can vary by model.</paragraph>
      <paragraph>The following example shows how to configure several of the available options.</paragraph>
      <heading level="2">Add system instructions</heading>
      <paragraph>System instructions let you steer the behavior of a model based on your specific needs and use cases.</paragraph>
      <paragraph>By giving the model system instructions, you provide the model additional context to understand the task, generate more customized responses, and adhere to specific guidelines over the full user interaction with the model. You can also specify product-level behavior by setting system instructions, separate from prompts provided by end users.</paragraph>
      <paragraph>You can set system instructions when you initialize your model:</paragraph>
      <paragraph>Then, you can send requests to the model as usual.</paragraph>
      <paragraph>For an interactive end to end example of using system instructions, see the system instructions colab.</paragraph>
      <heading level="2">What's next</heading>
      <paragraph>Now that you have explored the basics of the Gemini API, you might want to try:</paragraph>
      <list type="unordered">
        <item>Vision understanding: Learn how to use Gemini's native vision understanding to process images and videos.</item>
        <item>Audio understanding: Learn how to use Gemini's native audio understanding to process audio files.</item>
      </list>
      <code language="code">generateContent</code>
      <code language="code">streamGenerateContent</code>
      <code language="python">from google import genai
client = genai.Client(api_key=&quot;GEMINI_API_KEY&quot;)
response = client.models.generate_content(
    model=&quot;gemini-2.0-flash&quot;,
    contents=[&quot;How does AI work?&quot;])
print(response.text)
</code>
      <code language="python">from google import genai
client = genai.Client(api_key=&quot;GEMINI_API_KEY&quot;)
response = client.models.generate_content(
    model=&quot;gemini-2.0-flash&quot;,
    contents=[&quot;How does AI work?&quot;])
print(response.text)
</code>
      <code language="python">from PIL import Image
from google import genai
client = genai.Client(api_key=&quot;GEMINI_API_KEY&quot;)
image = Image.open(&quot;/path/to/organ.png&quot;)
response = client.models.generate_content(
    model=&quot;gemini-2.0-flash&quot;,
    contents=[image, &quot;Tell me about this instrument&quot;])
print(response.text)
</code>
      <code language="python">from PIL import Image
from google import genai
client = genai.Client(api_key=&quot;GEMINI_API_KEY&quot;)
image = Image.open(&quot;/path/to/organ.png&quot;)
response = client.models.generate_content(
    model=&quot;gemini-2.0-flash&quot;,
    contents=[image, &quot;Tell me about this instrument&quot;])
print(response.text)
</code>
      <code language="code">streamGenerateContent</code>
      <code language="python">from google import genai
client = genai.Client(api_key=&quot;GEMINI_API_KEY&quot;)
response = client.models.generate_content_stream(
    model=&quot;gemini-2.0-flash&quot;,
    contents=[&quot;Explain how AI works&quot;])
for chunk in response:
    print(chunk.text, end=&quot;&quot;)
</code>
      <code language="python">from google import genai
client = genai.Client(api_key=&quot;GEMINI_API_KEY&quot;)
response = client.models.generate_content_stream(
    model=&quot;gemini-2.0-flash&quot;,
    contents=[&quot;Explain how AI works&quot;])
for chunk in response:
    print(chunk.text, end=&quot;&quot;)
</code>
      <code language="code">generateContent</code>
      <code language="python">from google import genai
client = genai.Client(api_key=&quot;GEMINI_API_KEY&quot;)
chat = client.chats.create(model=&quot;gemini-2.0-flash&quot;)
response = chat.send_message(&quot;I have 2 dogs in my house.&quot;)
print(response.text)
response = chat.send_message(&quot;How many paws are in my house?&quot;)
print(response.text)
for message in chat._curated_history:
    print(f'role - {message.role}' end=&quot;: &quot;)
    print(message.parts[0].text)
</code>
      <code language="python">from google import genai
client = genai.Client(api_key=&quot;GEMINI_API_KEY&quot;)
chat = client.chats.create(model=&quot;gemini-2.0-flash&quot;)
response = chat.send_message(&quot;I have 2 dogs in my house.&quot;)
print(response.text)
response = chat.send_message(&quot;How many paws are in my house?&quot;)
print(response.text)
for message in chat._curated_history:
    print(f'role - {message.role}' end=&quot;: &quot;)
    print(message.parts[0].text)
</code>
      <code language="python">from google import genai
client = genai.Client(api_key=&quot;GEMINI_API_KEY&quot;)
chat = client.chats.create(model=&quot;gemini-2.0-flash&quot;)
response = chat.send_message_stream(&quot;I have 2 dogs in my house.&quot;)
for chunk in response:
    print(chunk.text, end=&quot;&quot;)
response = chat.send_message_stream(&quot;How many paws are in my house?&quot;)
for chunk in response:
    print(chunk.text, end=&quot;&quot;)
for message in chat._curated_history:
    print(f'role - {message.role}', end=&quot;: &quot;)
    print(message.parts[0].text)
</code>
      <code language="python">from google import genai
client = genai.Client(api_key=&quot;GEMINI_API_KEY&quot;)
chat = client.chats.create(model=&quot;gemini-2.0-flash&quot;)
response = chat.send_message_stream(&quot;I have 2 dogs in my house.&quot;)
for chunk in response:
    print(chunk.text, end=&quot;&quot;)
response = chat.send_message_stream(&quot;How many paws are in my house?&quot;)
for chunk in response:
    print(chunk.text, end=&quot;&quot;)
for message in chat._curated_history:
    print(f'role - {message.role}', end=&quot;: &quot;)
    print(message.parts[0].text)
</code>
      <code language="code">GenerationConfig</code>
      <code language="python">from google import genai
from google.genai import types
client = genai.Client(api_key=&quot;GEMINI_API_KEY&quot;)
response = client.models.generate_content(
    model=&quot;gemini-2.0-flash&quot;,
    contents=[&quot;Explain how AI works&quot;],
    config=types.GenerateContentConfig(
        max_output_tokens=500,
        temperature=0.1
    )
)
print(response.text)
</code>
      <code language="python">from google import genai
from google.genai import types
client = genai.Client(api_key=&quot;GEMINI_API_KEY&quot;)
response = client.models.generate_content(
    model=&quot;gemini-2.0-flash&quot;,
    contents=[&quot;Explain how AI works&quot;],
    config=types.GenerateContentConfig(
        max_output_tokens=500,
        temperature=0.1
    )
)
print(response.text)
</code>
      <code language="code">sys_instruct=&quot;You are a cat. Your name is Neko.&quot;
client = genai.Client(api_key=&quot;GEMINI_API_KEY&quot;)
response = client.models.generate_content(
    model=&quot;gemini-2.0-flash&quot;,
    config=types.GenerateContentConfig(
        system_instruction=sys_instruct),
    contents=[&quot;your prompt here&quot;]
)
</code>
      <code language="code">sys_instruct=&quot;You are a cat. Your name is Neko.&quot;
client = genai.Client(api_key=&quot;GEMINI_API_KEY&quot;)
response = client.models.generate_content(
    model=&quot;gemini-2.0-flash&quot;,
    config=types.GenerateContentConfig(
        system_instruction=sys_instruct),
    contents=[&quot;your prompt here&quot;]
)
</code>
    </content>
  </page>
  <page url="https://ai.google.dev/gemini-api/docs/text-generation">
    <title>Text generation | Gemini API | Google AI for Developers</title>
    <content>
      <heading level="1">Text generation</heading>
      <paragraph>Python Node.js Go REST</paragraph>
      <paragraph>The Gemini API can generate text output when provided text, images, video, and audio as input.</paragraph>
      <paragraph>This guide shows you how to generate text using the generateContent and streamGenerateContent methods. To learn about working with Gemini's vision and audio capabilities, refer to the Vision and Audio guides.</paragraph>
      <heading level="2">What's next</heading>
      <paragraph>Now that you have explored the basics of the Gemini API, you might want to try:</paragraph>
      <list type="unordered">
        <item>Vision understanding: Learn how to use Gemini's native vision understanding to process images and videos.</item>
        <item>Audio understanding: Learn how to use Gemini's native audio understanding to process audio files.</item>
      </list>
      <paragraph>Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.</paragraph>
      <paragraph>Last updated 2025-03-04 UTC.</paragraph>
      <code language="code">generateContent</code>
      <code language="code">streamGenerateContent</code>
    </content>
  </page>
</documentation>